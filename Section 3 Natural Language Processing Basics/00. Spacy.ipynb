{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Spacy installation\n",
    "#### Install using anaconda prompt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge spacy\n",
    "# Download lanaguage library\n",
    "# python -m spacy download en\n",
    "    # By default it will download only sm version of library\n",
    "    # In-case you want to download larger version \n",
    "       #  python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        ------------------------------------------------------------\n",
    "        \n",
    "Text        ---> Tokenizer --> Tagger --> Parser --> describe textData                -->        DOC\n",
    "\n",
    "        -------------------------NLP-----------------------------------\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(u'Tesla is looking at buying a new startup company of U.S. at $6 million')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla                PROPN                nsubj     \n",
      "is                   VERB                 aux       \n",
      "looking              VERB                 ROOT      \n",
      "at                   ADP                  prep      \n",
      "buying               VERB                 pcomp     \n",
      "a                    DET                  det       \n",
      "new                  ADJ                  amod      \n",
      "startup              ADJ                  amod      \n",
      "company              NOUN                 dobj      \n",
      "of                   ADP                  prep      \n",
      "U.S.                 PROPN                pobj      \n",
      "at                   ADP                  prep      \n",
      "$                    SYM                  quantmod  \n",
      "6                    NUM                  compound  \n",
      "million              NUM                  pobj      \n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(f'{token.text:{20}} {token.pos_:{20}} {token.dep_:<{10}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x2ad8be2edd8>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x2ad8d4888e8>),\n",
       " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x2ad8d488948>)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipeline\n",
    "#ner - Name entity recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc2 = nlp(u\"Tesla isn't looking   for any startup company anymore.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla                PROPN                nsubj     \n",
      "is                   VERB                 aux       \n",
      "n't                  ADV                  neg       \n",
      "looking              VERB                 ROOT      \n",
      "                     SPACE                          \n",
      "for                  ADP                  prep      \n",
      "any                  DET                  det       \n",
      "startup              ADJ                  amod      \n",
      "company              NOUN                 pobj      \n",
      "anymore              ADV                  advmod    \n",
      ".                    PUNCT                punct     \n"
     ]
    }
   ],
   "source": [
    "for token in doc2:\n",
    "    print(f'{token.text:{20}} {token.pos_:{20}} {token.dep_:<{10}}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = nlp(u\"During the podcast, which was streamed live,\\\n",
    "            Rogan lit a spliff, and Musk asked what it is. Rogan replied that it's \\\n",
    "           marijuana inside of tobacco. Rogan said Musk probably couldn't smoke it, \\\n",
    "           “because of stockholders,” and Musk replied asking whether it was legal. ...\\\n",
    "           Rogan asked as Musk smoked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#span\n",
    "#Even the slice of the document will act as a spacy tokens.\n",
    "sent_span = doc3[10:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.span.Span"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sent_span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "spacy.tokens.doc.Doc"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = nlp(u\"Trying to print different sentences as a different token. This is the first sentence. well, the second sentence started. Here comes the third one.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to print different sentences as a different token.\n",
      "This is the first sentence.\n",
      "well, the second sentence started.\n",
      "Here comes the third one.\n"
     ]
    }
   ],
   "source": [
    "for sentence in doc4.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4[10].is_sent_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
